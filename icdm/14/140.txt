
      Log-linear analysis is the primary statistical approach to discovering conditional dependencies between the variables of a dataset. What makes a good log-linear analysis method is twofold: high precision and statistical efficiency. High precision means that the risk of false discoveries should be kept very low. Discovery efficiency means that the method should discover actual associations with as few samples as possible. Classical approaches to log-linear analysis make use of X^2 tests to control this balance between quality and complexity. We present an information-theoretic approach to log-linear analysis. We show that our approach 1) requires significantly fewer samples to discover the true associations than statistical approaches - statistical efficiency - 2) controls for the risk of false discoveries as well as statistical approaches - high precision - and 3) can perform the discovery on datasets with hundreds of variables on a standard desktop computer - computational efficiency.
      