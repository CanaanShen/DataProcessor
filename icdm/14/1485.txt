
      How can we discern suspicious users from honest users in large online networks? Social networks and other web-services that incentivize popularity often suffer from fraudulent users deceptively boosting their customers' public image. This input is vacuous and sometimes harmful to the experiences of honest users. In response to this problem, a number of features and algorithms have been introduced in recent years with the aim of discerning suspicious users from honest users. These methods primarily employ eigenanalysis and spectral decomposition in order to find community structures and lockstep patterns indicative of naively-executed fraudulent activity. In this work, we take an adversarial approach and give detailed theoretical analysis to show that these state-of-the-art techniques are only effective in detecting blatant attacks and are easily evaded by intelligent attackers. From this analysis, we identify the practical implications for attacks on real data resulting from the blind-spots in modern detection schemes. In response, we propose a broad framework of various attack patterns and identify how different techniques should be used together to protect against attackers. Furthermore, we provide a (a) scalable and (b) complementary algorithm, fBox, for detecting attacks that previous methods miss. Lastly, we demonstrate that our algorithm is effective against stealth attacks of limited size in the presence of camouflage. We evaluate our algorithm on a 41.7 million node, 1.5 billion edge who-follows-whom social graph from Twitter in 2010 and identify many suspicious accounts which have persisted without suspension even to this day.
      