
      Multi-view data is very popular in real-world applications, as different view-points and various types of sensors help better represent data when fused across views or modalities. Samples from different views of the same class are less similar compared with the same view from different classes. We consider a more general case that prior view information of testing data is inaccessible in multi-view learning. Traditional multi-view learning algorithms, designed to obtain multiple view-specific linear projections, would fail without this prior information available, as they assumed the probe and gallery views were known in advance, so the correct view-specific projections were to be applied to better learn low-dimensional features. To address this, we propose a Low-Rank Common Subspace (LRCS) for multi-view data analysis, that seeks a common low-rank linear projection to mitigate the semantic gap among different views. The low-rank common projection can capture compatible intrinsic information across different views and well-align the within-class samples from different views. Furthermore, with a low-rank constraint on the view-specific projected data and that transformed by the common subspace, the within-class samples from multiple views would concentrate together. Different from the traditional supervised multi-view algorithms, our LRCS works in a weakly supervised way, where only the view information gets observed. Such a common projection can make our model more flexible when dealing with the problem of lacking prior view information of testing data. Two scenarios of experiments, robust subspace learning and transfer learning, are conducted to evaluate our algorithm. Experimental results on several multi-view datasets reveal that our proposed method outperforms state-of-the-art, even when compared to the supervised learning methods.
      