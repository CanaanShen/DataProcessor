
      Discretization of streaming numeric data has received surprisingly little attention. This might be because streaming data require incremental discretization with bins whose boundaries may vary over time and this is perceived as undesirable. We argue, to the contrary, that it can be desirable for a discretization to evolve in synchronization with an evolving data stream, even when the discretization is used with a learner that assumes that attribute values' meanings remain invariant over time. We examine the issues associated with discretization in the context of distribution drift and develop computationally efficient algorithms for discretization of stream data. We show that discretization can reduce the error of a classical incremental learner and that allowing a discretization to drift in synchronization with distribution drift can further reduce error.
      