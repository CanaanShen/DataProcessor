
      We address the issue of data fusion. Suppose that we are given two datasets, where some variables are different each other and others are the same. The goal of data fusion is to complement the missing unique variables in each dataset using the common variables. Data fusion facilitates inference over multiple independent and different datasets, which is an important data mining issues that affect many applications, such as recommendation, image reconstruction, or market analysis. In this paper, we propose a novel approach to data fusion using restricted Boltzmann machines (RBMs). In applying to data fusion, RBMs are able to model hidden patterns lying behind the two datasets with bipartite graph structure between hidden variables and observable ones. There is a bottleneck in the application of RBMs to data fusion: It is computationally expensive to learn RBMs from data with missing values. Therefore, we propose a new efficient algorithm for learning RBMs from missing data. This algorithm maximizes the lower bound on the observation likelihood, which can efficiently be computed. With artificial and real datasets, we empirically demonstrate that our RBM-based data fusion method significantly outperforms existing methods in terms of complement accuracy, particularly when the number of common variables is small. These results demonstrate an advantage of data fusion based on latent-variable modeling.
      